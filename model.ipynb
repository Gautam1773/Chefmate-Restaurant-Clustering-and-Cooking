{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering, MeanShift\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from joblib import load\n",
    "from joblib import dump\n",
    "import pickle\n",
    "import boto3\n",
    "from google.colab import userdata\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Access_key = userdata.get('access_key')\n",
    "Secret_key =userdata.get('secret_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# configuration setup\n",
    "s3_client = boto3.client(\n",
    "                          's3',\n",
    "                          aws_access_key_id = Access_key,\n",
    "                          aws_secret_access_key = Secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# MySQL\n",
    "server = 'endpoint'\n",
    "port = 3306\n",
    "user = 'admin'\n",
    "password = 'Gautam1773'\n",
    "database = 'chefmate'\n",
    "sqltype = \"mysql+mysqlconnector\"\n",
    "\n",
    "engine = sqlalchemy.create_engine(f'{sqltype}://{user}:{password}@{server}:{port}/{database}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# SQL query\n",
    "query = \"SELECT * FROM restaurant\"\n",
    "# Load data into a DataFrame\n",
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# remove one index\n",
    "df = df.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#  Select Relevant Columns\n",
    "features = df[['Cuisines', 'Restaurant_id', 'Aggregate_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#One-Hot Encoding\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "cuisines_encoded = encoder.fit_transform(features[['Cuisines']])\n",
    "cuisines_df = pd.DataFrame(cuisines_encoded, columns=encoder.get_feature_names_out(['Cuisines']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Prepare Data for Clustering\n",
    "numerical_features = features[['Restaurant_id', 'Aggregate_rating']]\n",
    "clustering_data = pd.concat([cuisines_df, numerical_features.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Determine Optimal Number of Clusters (Elbow Method)\n",
    "inertia = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(clustering_data)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(clustering_data, kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting Elbow Method\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(K_range, inertia, marker='o')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(K_range, silhouette_scores, marker='o')\n",
    "plt.title('Silhouette Score')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Clustering Algorithms\n",
    "best_k = K_range[silhouette_scores.index(max(silhouette_scores))]  # Optimal k from silhouette score\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(clustering_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(clustering_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "agglo = AgglomerativeClustering(n_clusters=best_k)\n",
    "agglo_labels = agglo.fit_predict(clustering_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=best_k)\n",
    "gmm_labels = gmm.fit_predict(clustering_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_clustering_model(model, data, model_name):\n",
    "    # Predict cluster labels\n",
    "    if model_name == 'KMeans':\n",
    "        labels = model.labels_  # KMeans has labels_ attribute after fitting\n",
    "    else:\n",
    "        labels = model.fit_predict(data)  # For other models, fit and predict\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    silhouette = silhouette_score(data, labels)\n",
    "    if model_name == 'KMeans':\n",
    "        inertia = model.inertia_  # Only for KMeans\n",
    "    else:\n",
    "        inertia = None  # Not applicable for other models\n",
    "\n",
    "    davies_bouldin = davies_bouldin_score(data, labels)\n",
    "    calinski_harabasz = calinski_harabasz_score(data, labels)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Silhouette Score: {silhouette:.4f}\")\n",
    "    if inertia is not None:\n",
    "        print(f\"Inertia: {inertia:.4f}\")\n",
    "    print(f\"Davies-Bouldin Index: {davies_bouldin:.4f}\")\n",
    "    print(f\"Calinski-Harabasz Index: {calinski_harabasz:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Evaluate all models\n",
    "evaluate_clustering_model(kmeans, clustering_data, 'KMeans')\n",
    "evaluate_clustering_model(dbscan, clustering_data, 'DBSCAN')\n",
    "evaluate_clustering_model(agglo, clustering_data, 'Agglomerative Clustering')\n",
    "#evaluate_clustering_model(mean_shift, clustering_data, 'Mean Shift')\n",
    "evaluate_clustering_model(gmm, clustering_data, 'Gaussian Mixture Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_clusters(data, labels, model_name):\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_data = pca.fit_transform(data)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=labels, cmap='viridis', marker='o', edgecolor='k', s=50)\n",
    "    plt.title(f'Clusters formed by {model_name}')\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Plot clusters for each model\n",
    "plot_clusters(clustering_data, kmeans.labels_, 'KMeans')\n",
    "plot_clusters(clustering_data, dbscan.labels_, 'DBSCAN')\n",
    "plot_clusters(clustering_data, agglo.labels_, 'Agglomerative Clustering')\n",
    "#plot_clusters(clustering_data, mean_shift.labels_, 'Mean Shift')\n",
    "plot_clusters(clustering_data, gmm.predict(clustering_data), 'Gaussian Mixture Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Save the Models\n",
    "with open('kmeans_model.pkl', 'wb') as f:\n",
    "    pickle.dump(kmeans, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# upload the kmeans_model to s3\n",
    "file_path = \"kmeans_model.pkl\"\n",
    "s3_client.upload_file(file_path,'chefmatebucket1','datas/kmeans_model.pkl') #folder/filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save the encoder\n",
    "with open('onehot_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df['Cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save cleaned df to a CSV file\n",
    "df.to_csv('Zomato_cluster_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# upload the cluster data to s3\n",
    "file_path = \"Zomato_cluster_data.csv\"\n",
    "s3_client.upload_file(file_path,'chefmatebucket1','datas/Zomato_cluster_data.csv') #folder/filename"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
